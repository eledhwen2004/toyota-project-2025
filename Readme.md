# Financial Data Integration and Calculation Project

This project aims to develop a comprehensive software solution for integrating, processing, and calculating financial data from multiple data providers. The system is designed to collect raw financial data, perform calculations, and disseminate the results.

## Overview

The system architecture involves several key components working together to achieve the project's goals. It is specifically designed to handle Forex (foreign exchange) data, with each data set including a unique identifier, bid price, ask price, and timestamp. [cite: 3, 4, 5, 6, 7]

## Key Components

1.  **Platform Applications:**
    * **Platform App 1:** Simulates a data provider using **TCP** for data streaming. [cite: 14, 15]
    * **Platform App 2:** Simulates a data provider using a **REST API** to provide data on request. [cite: 14, 23]
    * **Platform App n:** Represents the potential for additional platform applications using various protocols (e.g., FIX). [cite: 14]

2.  **Subscribers:**
    * Subscribers receive raw data from the Platform Applications. They are responsible for handling the different communication protocols (TCP, REST API, etc.) and forwarding the data to the core processing components. [cite: 28, 29, 30]

3.  **Hazelcast:**
    * Hazelcast is used as a distributed in-memory data grid. It serves two main purposes:
        * **Raw Rates:** Storing the raw data received from the Subscribers for quick access. [cite: 35, 36]
        * **Calculated Rates:** Storing the rates after calculations have been performed by the Coordinator. [cite: 35, 36]

4.  **Coordinator:**
    * The Coordinator is the central component of the application. It orchestrates the data flow, retrieves raw rates from Hazelcast, performs calculations to derive new financial data, and stores the calculated rates back in Hazelcast. [cite: 30, 31, 32, 33, 34]
    * The calculation methods are designed to be dynamic and configurable, allowing for the use of Java classes or scripting languages like JavaScript or Groovy. [cite: 42, 43, 44]

5.  **Kafka Producer:**
    * The Coordinator publishes the calculated rates to a Kafka message broker using a Kafka Producer. [cite: 41] This enables asynchronous processing and decouples the calculation logic from downstream consumers.

6.  **Kafka:**
    * Apache Kafka is a distributed streaming platform that acts as a central message broker. It receives the calculated rates from the Producer.

7.  **Kafka Consumer:**
    * A single Kafka Consumer is used to subscribe to the Kafka topic and process the calculated rates. [cite: 56, 57] This consumer is responsible for:
        * Persisting the calculated rates into a PostgreSQL database using JPA API and Hibernate. [cite: 57, 58]

8.  **Logger & Filebeat:**
    * The Logger component logs events and activities within the system (using Log4j2). [cite: 9, 10]
    * Filebeat is used to collect and forward these logs to OpenSearch for centralized logging and analysis.

9.  **PostgreSQL:**
    * PostgreSQL is the relational database used to store the processed financial data. [cite: 57, 58]

10. **OpenSearch:**
    * OpenSearch is used for storing and analyzing the logs generated by the system. [cite: 57]

## Project Specifics

* **Hazelcast Only:** This implementation uses Hazelcast for both raw and calculated rate storage, simplifying the data caching layer.
* **Single Kafka Consumer:** The system utilizes a single Kafka consumer to handle the persistence of calculated rates to the PostgreSQL database.

## Data Flow

1.  Platform Applications (TCP and REST API) provide raw financial data.
2.  Subscribers receive and forward this data.
3.  Hazelcast stores the raw data.
4.  The Coordinator retrieves raw data from Hazelcast, calculates new rates, and stores the results back in Hazelcast.
5.  The Coordinator publishes the calculated rates to Kafka.
6.  A single Kafka Consumer reads from Kafka and persists the data to PostgreSQL.
7.  System events are logged, and Filebeat forwards the logs to OpenSearch.

## Running the Application

**Assumed Module Directories (Example - adjust based on your actual project structure):**

* `toyota-tcp-rate-api-platform`
* `toyota-rest-rate-api-platform`
* `toyota-main-rate-api`

Before running each application, you need to package it using Maven. Open a terminal in each of the module directories and execute the following commands:

1.  **For TCP Platform Application:**
    ```bash
    cd toyota-tcp-rate-api-platform
    mvn clean package -DskipTests
    java -jar target/toyota-tcp-rate-api-platform-*.jar
    ```
    *(Replace `toyota-tcp-rate-api-platform-*.jar` with the actual name of your JAR file in the `target` directory.)*

2.  **For REST Platform Application:**
    ```bash
    cd toyota-rest-rate-api-platform
    mvn clean package -DskipTests
    java -jar target/toyota-rest-rate-api-platform-*.jar
    ```
    *(Replace `toyota-rest-rate-api-platform-*.jar` with the actual name of your JAR file in the `target` directory.)*

3.  **For Main Rate API (Coordinator and Processing Logic):**
    ```bash
    cd toyota-main-rate-api
    mvn clean package -DskipTests
    java -jar target/toyota-main-rate-api-*.jar
    ```
    *(Replace `toyota-main-rate-api-*.jar` with the actual name of your JAR file in the `target` directory.)*

**Important Notes:**

* Ensure Kafka, Hazelcast, and PostgreSQL are running and accessible before starting the application components.
* Configuration files for each component must be properly set up (e.g., database connection details, Kafka broker addresses, Hazelcast configuration). These configuration files are typically located within the packaged JAR or expected to be in a specific location relative to where the JAR is run.
* The `-DskipTests` flag is used to skip running unit tests during the packaging process. You can remove this flag if you want to run the tests.
* Refer to the individual component documentation for any specific command-line arguments or configuration options they might require.

## Project Structure

*(Optional: Briefly describe the project's directory structure and main packages)*

## Further Development

*(Optional: Mention any potential future enhancements or features)*
